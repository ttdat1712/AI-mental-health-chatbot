{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r8tj4FpcTIt2",
        "outputId": "42686234-bd54-4fba-c621-bac7fc37870b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mMounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets peft accelerate bitsandbytes scipy torch trl\n",
        "!pip install -q tensorboard\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z00vqCHO80N1",
        "outputId": "a643faa8-0dc8-43da-d02e-20a26d7ca6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "51f71654688647808e14e133238d05ca",
            "e45599fa4915401492d4b7f39e7ed577",
            "6581def6e25e4defb75e186fe47ae19a",
            "16516ff9c191454dbe44a53065996a66",
            "5bf49b71d4fa4522bd78e3548ce70ede",
            "865b7d2b38c140b28f8439d9337c9ab4",
            "c7fedcec9cf54ae6a3102965c9a5a516",
            "766aede04d9843338c7b2973c283c81a",
            "cb7ed66fe43147908a595cf0fc807e62",
            "f7a2558381914e5dacf159a8ef69d6cc",
            "20e4ba67b96a4b60aecb8f1f60f69199"
          ]
        },
        "collapsed": true,
        "id": "odzOnpUHG_6C",
        "outputId": "4659f515-a586-402d-a6c5-952ca1aa419d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n",
            "CUDA device: Tesla T4\n",
            "Dataset loaded from /content/dataset2.csv with shape: (20079, 4)\n",
            "                                               input  \\\n",
            "0  I'm finding it hard to low self-esteem and fee...   \n",
            "1  I'm overwhelmed by lack of motivation and feel...   \n",
            "2  I'm frustrated with physical exhaustion and fe...   \n",
            "3  I can't low self-esteem and feeling really dra...   \n",
            "4    I can't low self-esteem and feeling distracted.   \n",
            "\n",
            "                                              output  \\\n",
            "0  I'm really sorry to hear that. It's okay to fe...   \n",
            "1  It’s tough when your mind won’t stop racing. S...   \n",
            "2  It’s okay to feel like that sometimes. Let’s t...   \n",
            "3  It’s okay to feel worried, but remember that y...   \n",
            "4  I understand how exhausting that can be. Would...   \n",
            "\n",
            "                                            Question  \\\n",
            "0  Tôi cảm thấy thật khó để hạ thấp lòng tự trọng...   \n",
            "1  Tôi bị choáng ngợp vì thiếu động lực và cảm th...   \n",
            "2  Tôi chán nản vì thể chất kiệt sức và cảm thấy ...   \n",
            "3  Tôi không thể hạ thấp lòng tự trọng và cảm thấ...   \n",
            "4  Tôi không thể hạ thấp lòng tự trọng và cảm thấ...   \n",
            "\n",
            "                                              Answer  \n",
            "0  Tôi thực sự rất tiếc khi nghe điều đó. Đôi khi...  \n",
            "1  Thật khó khăn khi tâm trí bạn không ngừng chạy...  \n",
            "2  Đôi khi cảm thấy như vậy cũng không sao. Chúng...  \n",
            "3  Bạn có thể cảm thấy lo lắng nhưng hãy nhớ rằng...  \n",
            "4  Tôi hiểu điều đó có thể mệt mỏi đến mức nào. B...  \n",
            "Successfully loaded dataset from /content/dataset2.csv with 20079 examples\n",
            "--- Example 1 ---\n",
            "Question: Tôi thực sự lo lắng về chứng trầm cảm và cảm thấy căng thẳng.\n",
            "Answer: Bạn có thể cảm thấy lo lắng nhưng hãy nhớ rằng bạn không đơn độc trong việc này. Hãy nói về mối quan tâm của bạn.\n",
            "\n",
            "--- Example 2 ---\n",
            "Question: Tôi chán nản vì thường xuyên lo lắng và cảm thấy thực sự buồn.\n",
            "Answer: Sự kiệt sức thực sự rất khó khăn và điều quan trọng là bạn phải ưu tiên sức khỏe của mình. Bạn đã có thể nghỉ ngơi bất cứ lúc nào?\n",
            "\n",
            "--- Example 3 ---\n",
            "Question: Tôi không thể hạ thấp lòng tự trọng và cảm thấy kiệt sức về mặt tinh thần.\n",
            "Answer: Tôi thực sự rất tiếc khi biết bạn cảm thấy như vậy. Hiện tại bạn đang quản lý căng thẳng của mình như thế nào?\n",
            "\n",
            "--- Example 4 ---\n",
            "Question: Tôi đang gặp khó khăn với áp lực công việc và cảm thấy chán nản.\n",
            "Answer: Thật khó khăn khi tâm trí bạn không ngừng chạy đua. Đôi khi, hít một hơi thật sâu và tập trung vào hiện tại có thể hữu ích. Bạn có muốn thử điều đó không?\n",
            "\n",
            "--- Example 5 ---\n",
            "Question: Tôi không thể ngủ được và cảm thấy thực sự suy sụp.\n",
            "Answer: Sức khỏe tinh thần cũng quan trọng như sức khỏe thể chất. Bạn có muốn khám phá một số cách để cải thiện sức khỏe tinh thần của mình không?\n",
            "\n",
            "Enter your Hugging Face token: ··········\n",
            "Loading tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/tokenizer.json\n",
            "loading file tokenizer.model from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": false,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer vocab size: 128000\n",
            "Pad token: <|end_of_text|> (ID: 128001)\n",
            "EOS token: <|end_of_text|> (ID: 128001)\n",
            "Loading model. This may take a few minutes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/model.safetensors.index.json\n",
            "Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"use_cache\": false\n",
            "}\n",
            "\n",
            "target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51f71654688647808e14e133238d05ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
            "\n",
            "All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Llama-3.2-3B.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"temperature\": 0.6,\n",
            "  \"top_p\": 0.9\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import Dataset, concatenate_datasets\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
        "from trl import SFTTrainer\n",
        "logging.set_verbosity_info()\n",
        "import os\n",
        "\n",
        "# Force CUDA synchronous error reporting for debugging\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
        "\n",
        "# Model Configuration\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B\"  # 3B parameter model - good balance of size and performance\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Thesis/finetune_llama/output_llama_2\"\n",
        "\n",
        "# LoRA Configuration - optimized for Google Colab free GPU\n",
        "LORA_ALPHA = 16\n",
        "LORA_DROPOUT = 0.1\n",
        "LORA_R = 8  # Reduced rank for faster training\n",
        "\n",
        "DATASET_PATHS = [\n",
        "    \"/content/dataset2.csv\"\n",
        "]\n",
        "\n",
        "def prepare_dataset(dataset_path):\n",
        "    try:\n",
        "        df = pd.read_csv(dataset_path)\n",
        "        print(f\"Dataset loaded from {dataset_path} with shape: {df.shape}\")\n",
        "        print(df.head())\n",
        "\n",
        "        if all(col in df.columns for col in ['Question', 'Answer']):\n",
        "            df_filtered = df[['Question', 'Answer']]\n",
        "        elif all(col in df.columns for col in ['question', 'answer']):\n",
        "            df_filtered = df[['question', 'answer']]\n",
        "            df_filtered = df_filtered.rename(columns={\"question\": \"Question\", \"answer\": \"Answer\"})\n",
        "        else:\n",
        "            raise ValueError(f\"Dataset {dataset_path} doesn't have the required Question/Answer columns\")\n",
        "\n",
        "        # Clean the data - remove NaN values and convert to strings\n",
        "        df_filtered = df_filtered.dropna()\n",
        "        df_filtered['Question'] = df_filtered['Question'].astype(str)\n",
        "        df_filtered['Answer'] = df_filtered['Answer'].astype(str)\n",
        "\n",
        "        # Filter out very long sequences that might cause issues\n",
        "        df_filtered = df_filtered[\n",
        "            (df_filtered['Question'].str.len() < 1000) &\n",
        "            (df_filtered['Answer'].str.len() < 1000)\n",
        "        ]\n",
        "\n",
        "        dataset_dict = {\n",
        "            \"question\": df_filtered[\"Question\"].tolist(),\n",
        "            \"answer\": df_filtered[\"Answer\"].tolist()\n",
        "        }\n",
        "        return Dataset.from_dict(dataset_dict)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset from {dataset_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Load and prepare datasets\n",
        "datasets = []\n",
        "for path in DATASET_PATHS:\n",
        "    dataset = prepare_dataset(path)\n",
        "    if dataset is not None:\n",
        "        datasets.append(dataset)\n",
        "        print(f\"Successfully loaded dataset from {path} with {len(dataset)} examples\")\n",
        "\n",
        "if not datasets:\n",
        "    raise ValueError(\"No valid datasets were loaded. Please check your dataset paths and formats.\")\n",
        "\n",
        "combined_dataset = datasets[0] if len(datasets) == 1 else concatenate_datasets(datasets)\n",
        "combined_dataset = combined_dataset.shuffle(seed=42)\n",
        "\n",
        "# Display sample examples\n",
        "for i in range(min(5, len(combined_dataset))):\n",
        "    print(f\"--- Example {i+1} ---\")\n",
        "    print(\"Question:\", combined_dataset[i]['question'])\n",
        "    print(\"Answer:\", combined_dataset[i]['answer'])\n",
        "    print()\n",
        "\n",
        "# Login to Hugging Face\n",
        "from getpass import getpass\n",
        "from huggingface_hub import login\n",
        "hf_token = getpass(\"Enter your Hugging Face token: \")\n",
        "login(hf_token)\n",
        "\n",
        "# Initialize tokenizer with proper configuration\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    trust_remote_code=True,\n",
        "    use_fast=True,\n",
        "    padding_side=\"left\"  # Changed to left for LLaMA models\n",
        ")\n",
        "\n",
        "# Set pad token properly - crucial for avoiding CUDA errors\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "print(f\"Tokenizer vocab size: {tokenizer.vocab_size}\")\n",
        "print(f\"Pad token: {tokenizer.pad_token} (ID: {tokenizer.pad_token_id})\")\n",
        "print(f\"EOS token: {tokenizer.eos_token} (ID: {tokenizer.eos_token_id})\")\n",
        "\n",
        "# Configure quantization for efficient training\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "# Load the model with optimized configuration\n",
        "print(\"Loading model. This may take a few minutes...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    use_cache=False,  # Disable KV cache for training\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c139201c1e3c432fb6e5cd51dc05cd93",
            "7be3d660c0e9489cb30c31ed7dcb133b",
            "552071930edb4ad99bda7b09376397bd",
            "aa2ac38ca2154b18986fd32fd99794f4",
            "d21fdef140fc413fa0659fd6453a74ad",
            "cfd794a39ed7403a99a2f074a218ff93",
            "32aceddaff41484e8d90505834330e9f",
            "1327aa9f5f424b73ac06b71a04130d80",
            "18978a66ec504cd897968c351d4272f6",
            "0f316bb1af8544b794c454a555f4b2b4",
            "21519ae5779242c0830552aaf13ac339",
            "9b4756ecc1ce42108b2a82d3c75fa0a0",
            "8832f642940e4e2a960943cec0bf306c",
            "1a706c983f5045ff813cd031c6a58eff",
            "0b829ea809334198aa368565cb5420b2",
            "cc97cb8f5d0a4bf0ae80204ab752203d",
            "9edad2cf5b3742afae78a2e32e48458f",
            "1ec04309ea9a42878a1a5613fa60bb5e",
            "283b603ecbac4a939894f64366b4320b",
            "1821fa9bcf564558a1c6fddbb5cfe5f2",
            "163707720e4a4767a6ec05c08d78b9cf",
            "4cd354af5eef4091b615785dfc0e1d6e",
            "f090280f8af045509f2efdccc878de02",
            "a6cbfc91bc5f455e892ef4081a632edc",
            "0593b307094943b39100fbc8318a708b",
            "ccc8dad677a94260bf3fe4975a2df441",
            "6dceb971a4e74ccf99e41681bd961ff1",
            "3c97b55591e94745aac896055602afef",
            "e8dd674fba7741f396806c356dbe5c33",
            "808576312b684f84aaa0d06297be2434",
            "3e52ce0bd5e04a99a6e9d5ea1051d31b",
            "153837f2aaa74e2ea5aa442515355c82",
            "543ed702155b45c2848bd5b78a05dc29",
            "e8295483b765450797eb23718019aa87",
            "42522e9a85fb465ea4986172c6647ee1",
            "0b05af4204fd4422bf6113add052162e",
            "b24b1d9d5a8c4a54b75deea8a1fbf869",
            "a5265c35055047e3bacee93d5fbbff89",
            "1329d5c91db64d99b60cb7bb5be8948e",
            "0f246eaf6b2a41c98259c78fcfd1055b",
            "c6e4f5899ba54636a5d5010ca58b0abf",
            "f17484d451cd4e38ac92527cb957b128",
            "69ac749bb36340b8aec5cccac78b5f5e",
            "eaf043dc79e3425290bec25cbc5b4ae3"
          ]
        },
        "id": "DEuham8L_NG0",
        "outputId": "2dfd69ef-f7f4-4f9e-c719-f5761be85415",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 12,156,928 || all params: 3,224,906,752 || trainable%: 0.3770\n",
            "Trainable parameters: None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20079 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c139201c1e3c432fb6e5cd51dc05cd93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "PyTorch: setting up devices\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example of formatted prompt:\n",
            "<s>[INST] Bạn là cố vấn sức khỏe tâm thần AI. Cung cấp phản hồi đồng cảm, hỗ trợ và chuyên nghiệp để giúp bệnh nhân giải quyết các vấn đề sức khỏe tâm thần của họ.\n",
            "\n",
            "User: Tôi thực sự lo lắng về chứng trầm cảm và cảm thấy căng thẳng. [/INST]\n",
            "\n",
            "Assistant: Bạn có thể cảm thấy lo lắng nhưng hãy nhớ rằng bạn không đơn độc trong việc này. Hãy nói về mối quan tâm của bạn.</s>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/tokenizer.json\n",
            "loading file tokenizer.model from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding EOS to train dataset:   0%|          | 0/20079 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b4756ecc1ce42108b2a82d3c75fa0a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/20079 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f090280f8af045509f2efdccc878de02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/20079 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8295483b765450797eb23718019aa87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "Using auto half precision backend\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "The following columns in the Training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: answer, question, text. If answer, question, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "skipped Embedding(128256, 3072): 375.75M params\n",
            "skipped: 375.75M params\n",
            "***** Running training *****\n",
            "  Num examples = 20,079\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 1,000\n",
            "  Number of trainable parameters = 12,156,928\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 1:32:40, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.586500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.809700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.848800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.554900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.322000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.529600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.229800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.192700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.166700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.149100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.198900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.154100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.145700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.148500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.137600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.206300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.154600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.147900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.141800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.133000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.214500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.160100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.145500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.142400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.129900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.206200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.154900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.145100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.130600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.176700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.136800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.135200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.141000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.133300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.186600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.141000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.132900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.130100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.144800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.135200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.132200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.137100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.135900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.132400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.131800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.131700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.131500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.144400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.128200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.128600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.124100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.125300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.134000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.128900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.124200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.129400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.131200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.142400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.126000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.129000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.127400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.124600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.126400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.122200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.126400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.128100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.163300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.126800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.125600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.122400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.126700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.142900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.120100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.122700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.127700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.125500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.117900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.121400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.119800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.121300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.126500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.113300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.118900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.121300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.122700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.178800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.133200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.121900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.120600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.123900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.150600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.117600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.116300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.119700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.123800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-50\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-50/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-50/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-100\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-100/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-100/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-150\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-150/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-150/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-200\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-200/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-200/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-250\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-250/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-250/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-300\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-300/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-300/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-350\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-350/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-350/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-400\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-400/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-400/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-450\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-450/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-450/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-550\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-550/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-550/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-600\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-600/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-600/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-650\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-650/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-650/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-700\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-700/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-700/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-750\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-750/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-750/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-800\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-800/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-800/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-850\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-850/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-850/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-900\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-900/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-900/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-950\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-950/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-950/special_tokens_map.json\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-1000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/checkpoint-1000/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 24,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 32.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Thesis/finetune_llama/output_llama_2/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# Prepare the model for training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# Define LoRA configuration optimized for LLaMA-3\n",
        "lora_config = LoraConfig(\n",
        "    r=LORA_R,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        # Remove these - they don't exist in LLaMA-3.2 architecture\n",
        "        # \"attention.wq\",\n",
        "        # \"attention.wk\",\n",
        "        # \"attention.wv\",\n",
        "        # \"attention.wo\"\n",
        "    ],\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "print(f\"Trainable parameters: {model.print_trainable_parameters()}\")\n",
        "\n",
        "def formatting_prompts_func(example):\n",
        "    \"\"\"Format prompts according to LLaMA-3's expected format.\"\"\"\n",
        "    question = str(example[\"question\"]).strip()  # Ensure string and remove whitespace\n",
        "    answer = str(example[\"answer\"]).strip()\n",
        "\n",
        "    # Validate inputs aren't empty\n",
        "    if not question or not answer:\n",
        "        return {\"text\": \"\"}\n",
        "\n",
        "    # LLaMA-3 specific prompt format\n",
        "    system_prompt = \"Bạn là cố vấn sức khỏe tâm thần AI. Cung cấp phản hồi đồng cảm, hỗ trợ và chuyên nghiệp để giúp bệnh nhân giải quyết các vấn đề sức khỏe tâm thần của họ.\"\n",
        "\n",
        "    # Format following LLaMA-3's chat template with proper tokens\n",
        "    formatted_text = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{answer}<|eot_id|>\"\n",
        "\n",
        "    return {\"text\": formatted_text}\n",
        "\n",
        "# Apply formatting to dataset with error handling\n",
        "print(\"Formatting dataset...\")\n",
        "try:\n",
        "    formatted_dataset = combined_dataset.map(\n",
        "        formatting_prompts_func,\n",
        "        remove_columns=combined_dataset.column_names\n",
        "    )\n",
        "\n",
        "    # Filter out empty texts\n",
        "    formatted_dataset = formatted_dataset.filter(lambda x: len(x[\"text\"]) > 0)\n",
        "\n",
        "    print(f\"Formatted dataset size: {len(formatted_dataset)}\")\n",
        "    print(\"\\nExample of formatted prompt:\")\n",
        "    print(formatted_dataset[0]['text'][:500] + \"...\" if len(formatted_dataset[0]['text']) > 500 else formatted_dataset[0]['text'])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during dataset formatting: {e}\")\n",
        "    raise\n",
        "\n",
        "# Test tokenization on formatted data\n",
        "print(\"\\nTesting tokenization on formatted data...\")\n",
        "try:\n",
        "    sample_text = formatted_dataset[0][\"text\"]\n",
        "    tokens = tokenizer(\n",
        "        sample_text,\n",
        "        truncation=True,\n",
        "        padding=False,  # Don't pad single example\n",
        "        max_length=1024,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    print(f\"Tokenization successful!\")\n",
        "    print(f\"Input shape: {tokens['input_ids'].shape}\")\n",
        "    print(f\"Max token ID: {tokens['input_ids'].max().item()}\")\n",
        "    print(f\"Vocab size: {tokenizer.vocab_size}\")\n",
        "\n",
        "    # Critical check: ensure no token IDs exceed vocabulary\n",
        "    if tokens['input_ids'].max().item() >= tokenizer.vocab_size:\n",
        "        raise ValueError(f\"Token ID exceeds vocab size: {tokens['input_ids'].max().item()} >= {tokenizer.vocab_size}\")\n",
        "\n",
        "    # Move to GPU to test\n",
        "    if torch.cuda.is_available():\n",
        "        tokens = {k: v.cuda() for k, v in tokens.items()}\n",
        "        print(\"Successfully moved tokens to GPU\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Tokenization test failed: {e}\")\n",
        "    print(\"This indicates an issue with your data or tokenizer setup\")\n",
        "    raise\n",
        "\n",
        "# Training arguments optimized for 3B model on Google Colab free GPU\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    max_steps=1000,\n",
        "    per_device_train_batch_size=1,  # Keep batch size at 1 for 3B model\n",
        "    gradient_accumulation_steps=8,  # Increased for more stable training\n",
        "    gradient_checkpointing=True,\n",
        "    save_steps=50,  # Save more frequently\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-4,  # Slightly higher learning rate for faster convergence\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    bf16=False,  # Explicitly disable bf16\n",
        "    optim=\"paged_adamw_8bit\",  # Use 8-bit optimizer for memory efficiency\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.03,  # Shorter warmup\n",
        "    group_by_length=True,\n",
        "    dataloader_pin_memory=False,  # Disable to reduce memory pressure\n",
        "    dataloader_num_workers=0,  # Disable multiprocessing\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"tensorboard\",\n",
        "    # Add these for stability\n",
        "    save_safetensors=True,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# Initialize trainer with additional parameters for stability\n",
        "try:\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=formatted_dataset,\n",
        "        dataset_text_field=\"text\",\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=1024,  # Reasonable max length\n",
        "        packing=False,  # Disable packing to avoid issues\n",
        "    )\n",
        "\n",
        "    print(\"Trainer initialized successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Trainer initialization failed: {e}\")\n",
        "    raise\n",
        "\n",
        "# Clear cache before training\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Train the model with error handling\n",
        "print(\"Starting training...\")\n",
        "try:\n",
        "    trainer.train()\n",
        "    print(\"Training completed successfully!\")\n",
        "\n",
        "except RuntimeError as e:\n",
        "    if \"CUDA\" in str(e):\n",
        "        print(f\"CUDA error during training: {e}\")\n",
        "        print(\"\\nTroubleshooting suggestions:\")\n",
        "        print(\"1. Reduce max_seq_length to 512\")\n",
        "        print(\"2. Reduce gradient_accumulation_steps to 4\")\n",
        "        print(\"3. Check your dataset for unusual characters\")\n",
        "        print(\"4. Try restarting your runtime\")\n",
        "    raise\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Training failed: {e}\")\n",
        "    raise\n",
        "\n",
        "# Save the trained model\n",
        "print(\"Saving model...\")\n",
        "try:\n",
        "    trainer.save_model()\n",
        "    tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "    print(f\"Model saved successfully to {OUTPUT_DIR}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error saving model: {e}\")\n",
        "    raise\n",
        "\n",
        "# Test the trained model\n",
        "print(\"\\nTesting trained model...\")\n",
        "try:\n",
        "    # Load the saved model for testing\n",
        "    model.eval()\n",
        "\n",
        "    test_question = \"Tôi cảm thấy lo lắng về công việc\"\n",
        "    test_prompt = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nBạn là cố vấn sức khỏe tâm thần AI.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{test_question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
        "\n",
        "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=100,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"Test response: {response}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Model testing failed: {e}\")\n",
        "    print(\"Model was saved but testing failed - this might be normal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28M9cXsC_R9z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "9d0302ae-a784-4a03-9bb2-b98c15d8a82b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualization of training progress\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logs = trainer.state.log_history\n",
        "steps = [log[\"step\"] for log in logs if \"loss\" in log and \"step\" in log]\n",
        "losses = [log[\"loss\"] for log in logs if \"loss\" in log and \"step\" in log]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(steps, losses, marker='o')\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss over Steps\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_merged_model(model_path, save_path):\n",
        "    print(f\"Creating merged model at {save_path}...\")\n",
        "\n",
        "    # Clear GPU cache before loading\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    try:\n",
        "        # Load base model WITHOUT quantization for merging\n",
        "        # Quantized models cannot be properly merged and saved\n",
        "        print(\"Loading base model...\")\n",
        "        base_model = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.float16,  # Use float16 instead of quantization\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "\n",
        "        print(\"Loading LoRA adapter...\")\n",
        "        # Load the PEFT model\n",
        "        model = PeftModel.from_pretrained(base_model, model_path)\n",
        "\n",
        "        print(\"Merging LoRA weights with base model...\")\n",
        "        # Merge and unload the adapter weights\n",
        "        merged_model = model.merge_and_unload()\n",
        "\n",
        "        # Create save directory if it doesn't exist\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "        print(\"Saving merged model...\")\n",
        "        # Save the merged model\n",
        "        merged_model.save_pretrained(\n",
        "            save_path,\n",
        "            safe_serialization=True,  # Use safetensors format\n",
        "            max_shard_size=\"5GB\"  # Prevent huge single files\n",
        "        )\n",
        "\n",
        "        # Save tokenizer\n",
        "        tokenizer.save_pretrained(save_path)\n",
        "\n",
        "        print(f\"Merged model saved to {save_path}\")\n",
        "\n",
        "        # Clean up memory\n",
        "        del base_model, model, merged_model\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during model merging: {e}\")\n",
        "        print(\"Common issues:\")\n",
        "        print(\"1. Not enough GPU/RAM memory\")\n",
        "        print(\"2. Corrupted adapter weights\")\n",
        "        print(\"3. Path issues\")\n",
        "        return False\n",
        "\n",
        "# Alternative function for saving quantized model (if you want to keep quantization)\n",
        "def save_quantized_adapter(model_path, save_path):\n",
        "    \"\"\"\n",
        "    Save the adapter separately (keeps quantization, smaller file size)\n",
        "    Use this if you don't need a single merged model file\n",
        "    \"\"\"\n",
        "    print(f\"Saving adapter model at {save_path}...\")\n",
        "\n",
        "    try:\n",
        "        # Just copy the adapter files\n",
        "        import shutil\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "        # Copy adapter files\n",
        "        for file in os.listdir(model_path):\n",
        "            if file.endswith(('.bin', '.json', '.safetensors')):\n",
        "                shutil.copy2(os.path.join(model_path, file), save_path)\n",
        "\n",
        "        # Save tokenizer\n",
        "        tokenizer.save_pretrained(save_path)\n",
        "\n",
        "        # Save a config file indicating this needs the base model\n",
        "        config = {\n",
        "            \"base_model\": MODEL_NAME,\n",
        "            \"adapter_path\": save_path,\n",
        "            \"model_type\": \"peft_adapter\"\n",
        "        }\n",
        "\n",
        "        import json\n",
        "        with open(os.path.join(save_path, \"adapter_config.json\"), \"w\") as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        print(f\"Adapter saved to {save_path}\")\n",
        "        print(\"To use this model, load the base model and then apply this adapter\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving adapter: {e}\")\n",
        "        return False\n",
        "\n",
        "# Function to test the merged model\n",
        "def test_merged_model(model_path):\n",
        "    \"\"\"Test the merged model to make sure it works\"\"\"\n",
        "    print(\"Testing merged model...\")\n",
        "\n",
        "    try:\n",
        "        # Load the merged model\n",
        "        test_model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_path,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.float16\n",
        "        )\n",
        "\n",
        "        test_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "        # Test generation\n",
        "        test_prompt = \"Xin chào, tôi cần hỗ trợ\"\n",
        "        inputs = test_tokenizer(test_prompt, return_tensors=\"pt\").to(test_model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = test_model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=50,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=test_tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        response = test_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        print(f\"Test successful! Response: {response}\")\n",
        "\n",
        "        # Clean up\n",
        "        del test_model, test_tokenizer\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Main execution\n",
        "print(\"Starting model merging process...\")\n",
        "\n",
        "# Try to save merged model first\n",
        "success = save_merged_model(OUTPUT_DIR, \"/content/drive/MyDrive/Thesis/finetune_llama/llama_finetune_2\")\n",
        "\n",
        "if success:\n",
        "    print(\"Merged model saved successfully!\")\n",
        "\n",
        "    # Test the merged model\n",
        "    if test_merged_model(\"/content/drive/MyDrive/Thesis/finetune_llama/llama_finetune_2\"):\n",
        "        print(\"Model testing passed!\")\n",
        "    else:\n",
        "        print(\"Model testing failed - check the saved model\")\n",
        "\n",
        "else:\n",
        "    print(\"Merging failed. Trying to save as adapter instead...\")\n",
        "    # If merging fails, save as adapter\n",
        "    adapter_success = save_quantized_adapter(OUTPUT_DIR, \"/content/drive/MyDrive/Thesis/finetune_llama/llama_adapter_2\")\n",
        "\n",
        "    if adapter_success:\n",
        "        print(\"Adapter saved successfully!\")\n",
        "        print(\"To use this model later:\")\n",
        "        print(\"1. Load the base model with quantization\")\n",
        "        print(\"2. Apply the adapter using PeftModel.from_pretrained()\")\n",
        "    else:\n",
        "        print(\"Both merging and adapter saving failed!\")\n",
        "\n",
        "print(\"Process completed!\")"
      ],
      "metadata": {
        "id": "F9lVD0gVxIs5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51f71654688647808e14e133238d05ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e45599fa4915401492d4b7f39e7ed577",
              "IPY_MODEL_6581def6e25e4defb75e186fe47ae19a",
              "IPY_MODEL_16516ff9c191454dbe44a53065996a66"
            ],
            "layout": "IPY_MODEL_5bf49b71d4fa4522bd78e3548ce70ede"
          }
        },
        "e45599fa4915401492d4b7f39e7ed577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865b7d2b38c140b28f8439d9337c9ab4",
            "placeholder": "​",
            "style": "IPY_MODEL_c7fedcec9cf54ae6a3102965c9a5a516",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6581def6e25e4defb75e186fe47ae19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_766aede04d9843338c7b2973c283c81a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb7ed66fe43147908a595cf0fc807e62",
            "value": 2
          }
        },
        "16516ff9c191454dbe44a53065996a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7a2558381914e5dacf159a8ef69d6cc",
            "placeholder": "​",
            "style": "IPY_MODEL_20e4ba67b96a4b60aecb8f1f60f69199",
            "value": " 2/2 [00:42&lt;00:00, 19.36s/it]"
          }
        },
        "5bf49b71d4fa4522bd78e3548ce70ede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "865b7d2b38c140b28f8439d9337c9ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7fedcec9cf54ae6a3102965c9a5a516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "766aede04d9843338c7b2973c283c81a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb7ed66fe43147908a595cf0fc807e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7a2558381914e5dacf159a8ef69d6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e4ba67b96a4b60aecb8f1f60f69199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c139201c1e3c432fb6e5cd51dc05cd93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7be3d660c0e9489cb30c31ed7dcb133b",
              "IPY_MODEL_552071930edb4ad99bda7b09376397bd",
              "IPY_MODEL_aa2ac38ca2154b18986fd32fd99794f4"
            ],
            "layout": "IPY_MODEL_d21fdef140fc413fa0659fd6453a74ad"
          }
        },
        "7be3d660c0e9489cb30c31ed7dcb133b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfd794a39ed7403a99a2f074a218ff93",
            "placeholder": "​",
            "style": "IPY_MODEL_32aceddaff41484e8d90505834330e9f",
            "value": "Map: 100%"
          }
        },
        "552071930edb4ad99bda7b09376397bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1327aa9f5f424b73ac06b71a04130d80",
            "max": 20079,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18978a66ec504cd897968c351d4272f6",
            "value": 20079
          }
        },
        "aa2ac38ca2154b18986fd32fd99794f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f316bb1af8544b794c454a555f4b2b4",
            "placeholder": "​",
            "style": "IPY_MODEL_21519ae5779242c0830552aaf13ac339",
            "value": " 20079/20079 [00:02&lt;00:00, 7799.13 examples/s]"
          }
        },
        "d21fdef140fc413fa0659fd6453a74ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd794a39ed7403a99a2f074a218ff93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32aceddaff41484e8d90505834330e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1327aa9f5f424b73ac06b71a04130d80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18978a66ec504cd897968c351d4272f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f316bb1af8544b794c454a555f4b2b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21519ae5779242c0830552aaf13ac339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b4756ecc1ce42108b2a82d3c75fa0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8832f642940e4e2a960943cec0bf306c",
              "IPY_MODEL_1a706c983f5045ff813cd031c6a58eff",
              "IPY_MODEL_0b829ea809334198aa368565cb5420b2"
            ],
            "layout": "IPY_MODEL_cc97cb8f5d0a4bf0ae80204ab752203d"
          }
        },
        "8832f642940e4e2a960943cec0bf306c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9edad2cf5b3742afae78a2e32e48458f",
            "placeholder": "​",
            "style": "IPY_MODEL_1ec04309ea9a42878a1a5613fa60bb5e",
            "value": "Adding EOS to train dataset: 100%"
          }
        },
        "1a706c983f5045ff813cd031c6a58eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283b603ecbac4a939894f64366b4320b",
            "max": 20079,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1821fa9bcf564558a1c6fddbb5cfe5f2",
            "value": 20079
          }
        },
        "0b829ea809334198aa368565cb5420b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_163707720e4a4767a6ec05c08d78b9cf",
            "placeholder": "​",
            "style": "IPY_MODEL_4cd354af5eef4091b615785dfc0e1d6e",
            "value": " 20079/20079 [00:01&lt;00:00, 17232.20 examples/s]"
          }
        },
        "cc97cb8f5d0a4bf0ae80204ab752203d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9edad2cf5b3742afae78a2e32e48458f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ec04309ea9a42878a1a5613fa60bb5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "283b603ecbac4a939894f64366b4320b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1821fa9bcf564558a1c6fddbb5cfe5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "163707720e4a4767a6ec05c08d78b9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd354af5eef4091b615785dfc0e1d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f090280f8af045509f2efdccc878de02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6cbfc91bc5f455e892ef4081a632edc",
              "IPY_MODEL_0593b307094943b39100fbc8318a708b",
              "IPY_MODEL_ccc8dad677a94260bf3fe4975a2df441"
            ],
            "layout": "IPY_MODEL_6dceb971a4e74ccf99e41681bd961ff1"
          }
        },
        "a6cbfc91bc5f455e892ef4081a632edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c97b55591e94745aac896055602afef",
            "placeholder": "​",
            "style": "IPY_MODEL_e8dd674fba7741f396806c356dbe5c33",
            "value": "Tokenizing train dataset: 100%"
          }
        },
        "0593b307094943b39100fbc8318a708b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808576312b684f84aaa0d06297be2434",
            "max": 20079,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e52ce0bd5e04a99a6e9d5ea1051d31b",
            "value": 20079
          }
        },
        "ccc8dad677a94260bf3fe4975a2df441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_153837f2aaa74e2ea5aa442515355c82",
            "placeholder": "​",
            "style": "IPY_MODEL_543ed702155b45c2848bd5b78a05dc29",
            "value": " 20079/20079 [00:11&lt;00:00, 1243.13 examples/s]"
          }
        },
        "6dceb971a4e74ccf99e41681bd961ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c97b55591e94745aac896055602afef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8dd674fba7741f396806c356dbe5c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "808576312b684f84aaa0d06297be2434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e52ce0bd5e04a99a6e9d5ea1051d31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "153837f2aaa74e2ea5aa442515355c82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "543ed702155b45c2848bd5b78a05dc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8295483b765450797eb23718019aa87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42522e9a85fb465ea4986172c6647ee1",
              "IPY_MODEL_0b05af4204fd4422bf6113add052162e",
              "IPY_MODEL_b24b1d9d5a8c4a54b75deea8a1fbf869"
            ],
            "layout": "IPY_MODEL_a5265c35055047e3bacee93d5fbbff89"
          }
        },
        "42522e9a85fb465ea4986172c6647ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1329d5c91db64d99b60cb7bb5be8948e",
            "placeholder": "​",
            "style": "IPY_MODEL_0f246eaf6b2a41c98259c78fcfd1055b",
            "value": "Truncating train dataset: 100%"
          }
        },
        "0b05af4204fd4422bf6113add052162e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6e4f5899ba54636a5d5010ca58b0abf",
            "max": 20079,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f17484d451cd4e38ac92527cb957b128",
            "value": 20079
          }
        },
        "b24b1d9d5a8c4a54b75deea8a1fbf869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69ac749bb36340b8aec5cccac78b5f5e",
            "placeholder": "​",
            "style": "IPY_MODEL_eaf043dc79e3425290bec25cbc5b4ae3",
            "value": " 20079/20079 [00:00&lt;00:00, 277702.44 examples/s]"
          }
        },
        "a5265c35055047e3bacee93d5fbbff89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1329d5c91db64d99b60cb7bb5be8948e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f246eaf6b2a41c98259c78fcfd1055b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6e4f5899ba54636a5d5010ca58b0abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17484d451cd4e38ac92527cb957b128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69ac749bb36340b8aec5cccac78b5f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaf043dc79e3425290bec25cbc5b4ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}